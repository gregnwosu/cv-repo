<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Greg Nwosu" />
  <title>CV</title>
  <style type="text/css">
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
</head>
<body>
<div id="header">
<h1 class="title">CV</h1>
<h2 class="author">Greg Nwosu</h2>
</div>
<h1 id="summary">Summary</h1>
<p>I'm known for having a can-do attitude, I find solutions where most
others can't. I often pioneer new approaches for teams to get around
issues and find approaches to issues that most see as unsurmountable.
I'm friendly and fit in, I bring up the quality of the less experienced
and love to learn from anyone that I can. I have good knowledge of Java
, Python , Scala, and Haskell, SQL, bash shell scripting. I have
experience with different cloud platforms GCP, Azure and AWS. I love
learning new things and have a passion for trading. I have deep
knowledge of Agile/Scrum, and I've been on many teams in the past and
draw on this experience of what works to figure out a way forward when
things get difficult.</p>
<p>I am <a
href="https://www.linkedin.com/feed/update/urn:li:activity:6073160702284091392">certified</a>
in machine learning from Stanford University’s <a
href="https://www.coursera.org/learn/machine-learning">course</a>. I’m a
<a
href="https://s3-us-west-2.amazonaws.com/udacity-printer/production/certificates/4032c6ab-8874-4854-abfd-3fc33dd75e07.pdf">graduate</a>
of <a href="https://classroom.udacity.com/nanodegrees/nd101">Udacity’s
Deep Learning Foundation Course</a> and now I'm halfway through the <a
href="https://learn.udacity.com/nanodegrees/nd893/">Udacity’s Deep
Reinforcement Learning NanoDegree</a>. My goal is to continue in the
position of being adept in cutting-edge machine learning techniques and
data science together with my current skills in big data engineering and
ETL.</p>
<h1 id="current-interests">Current Interests</h1>
<ul>
<li>Algo-Trading, wrote a home project that analyses candles and
recommends trades based on technical analysis.</li>
<li>Arbitrage: wrote a system that uses, bellman ford algorithm to find
negative weight cycles in currencies so I can make money by transferring
money between currencies at my bank.</li>
<li>Intermediate Advanced <a
href="https://github.com/gregnwosu/haskellbook">Haskell
programming</a></li>
<li>deep reinforcement learning.</li>
<li><a
href="https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/">category
theory</a></li>
<li>Bayesian Methods for Data Analytics.</li>
<li>Machine Learning, started playing with Large Language Models</li>
</ul>
<p>Other hobbies include:</p>
<ul>
<li>Cycling</li>
<li>Callisthenics</li>
<li>studying civil litigation and human rights law</li>
<li>Zen Meditation.</li>
<li>I have also trained to teach adults and am a mentor to children
learning to code at <a
href="https://www.dragonhall.org.uk/coderdojo/">CoderDojo</a>.</li>
</ul>
<h1 id="commercial-technical-experience">Commercial &amp; Technical
Experience</h1>
<h2 id="october-2021---present-shell">October 2021 - Present : <a
href="http://shell.com">Shell</a></h2>
<h3 id="responsibilities">Responsibilities</h3>
<ul>
<li>Front Office , Author and Designer of <a
href="https://app.powerbi.com/groups/me/apps/ab5daed7-88c8-4b35-9691-71bb9e2d751c/reports/22a243ae-1a44-4ec7-b9f3-5111615a3c2b/ReportSection?ctid=db1e96a8-a3da-442a-930b-235cac24cd5c&amp;bookmarkGuid=Bookmark858b0d79a416a133d321">Power
Purchase Agreements Reconciliation Tool</a> Technical</li>
</ul>
<p>Lead Engineer, Designer, Developer</p>
<ul>
<li>Front Office , <a
href="https://adb-8189235268511358.18.azuredatabricks.net/?o=8189235268511358#notebook/4039834138178088/dashboard/1665125115797297/present">Power
Purchase Agreement Inter-book Transfer Tool</a> Lead Engineer, Designer,
developer</li>
</ul>
<h3 id="technologies">Technologies</h3>
<p>Azure Data Factory, Azure DevOps, Databricks, Pyspark, Databricks
DeltaLake, Databricks DeltaLive, Databricks Auto-loader</p>
<h3 id="achievements">Achievements:</h3>
<ul>
<li><p>Wrote a spark UDF that decompresses zip files, zip decompression
is not supported in spark, but I managed to support it, without having
to write to temporary storage.</p></li>
<li><p>(re)Wrote <a
href="https://app.powerbi.com/groups/me/apps/ab5daed7-88c8-4b35-9691-71bb9e2d751c/reports/22a243ae-1a44-4ec7-b9f3-5111615a3c2b/ReportSection?ctid=db1e96a8-a3da-442a-930b-235cac24cd5c&amp;bookmarkGuid=Bookmark858b0d79a416a133d321">a
reconciliation tool to reconcile Power Purchase Contracts</a>
(PPAs)</p></li>
</ul>
<p>between Shell and a third-party broker within the first 6 months of
joining. Currently, the system is used directly by traders on its newly
formed power trading desk. The system provides near real-time tracking
of PPAs from broker order books through shell middle-ware and into the
Shell order books. The system achieved 4 x9's up-time and became so
reliable it was moved to a "run and support" model. The system includes
data-quality analysis, slicers and dice controls, summaries, drill-down
and graphical visualizations.</p>
<ul>
<li>The existing system for transferring PPAs from the broker to Shell
was slow and unreliable. Delivered <a
href="https://adb-8189235268511358.18.azuredatabricks.net/?o=8189235268511358#notebook/4039834138178088/dashboard/1665125115797297/present">a
real-time streaming support system Inter-book Transfer Tool for
transferring trades</a></li>
</ul>
<p>between an external PPA broker and Shell. The system generates a VWAP
curve from energy price forecast data and executes orders to cover
predicted liabilities of third-party renewable energy contracts. The
system uses Databricks DeltaLake format for full audit coverage over
time. It is possible to view and query the state of the system at any
time in the past. The new Power Purchase Inter-Book transfer tool
leverages DeltaLive and Databricks auto loader for real-time streaming
updates, so that traders can ensure timely transfer of PPAs to the Shell
order book.</p>
<h3 id="qualifications">Qualifications</h3>
<ul>
<li>Mennta <a
href="https://www.menntalive.com/product?catalog=ITT">Introduction To
Trading</a></li>
<li>Mennta <a
href="https://www.menntalive.com/product?catalog=ICD">Introduction To
Commodity Derivatives</a></li>
</ul>
<h2 id="march-2021---september-2021-gousto">March 2021 - September 2021
: <a href="https://www.gousto.co.uk/">Gousto</a></h2>
<h3 id="responsibilities-1">Responsibilities</h3>
<p>Senior Data Engineer.</p>
<h3 id="technologies-1">Technologies</h3>
<p>AWS DMS, AWS Glue, AWS EC2, AWS EMR, AWS Cloudformation, Python,
Databricks Spark, Databrick Delta Lake,</p>
<h3 id="airflow-kubernetes">Airflow, Kubernetes</h3>
<h3 id="achievements-1">Achievements:</h3>
<ul>
<li>Wrote a proof of concept to show how to attach hooks to spark
streams</li>
</ul>
<p>in python, to enable automatic alerting on ingestion failure of a
streaming process. – Proposed two ways, one of which used the sparks
internal python java bridge.</p>
<ul>
<li>introduced BDD to help BAs verify business logic.</li>
<li>Used AWS DMS Service to safely migrate data from databases into AWS
S3</li>
</ul>
<p>storage in real-time.</p>
<h2 id="march-2019---march-2021-shell">March 2019 - March 2021 : <a
href="http://shell.com">Shell</a></h2>
<h3 id="responsibilities-2">Responsibilities</h3>
<ol>
<li><p>Part of the SWAT (SoftWare /Analytics Team) team in The Agile Hub
tasked with improving the architectural approach</p>
<p>and development of extracting business value (monetizing) of data
from underachieving shell projects. Projects usually exist for 5</p>
<ul>
<li>7 weeks. Projects typically deliver technical advisory reports and a
proof of concept.</li>
</ul></li>
<li><p>Cargo Tracking wrote software for front desk trading analysts
that provide consensus</p>
<p>on the location of crude and distillates from various
providers.</p></li>
</ol>
<h3 id="technologies-2">Technologies</h3>
<p>Helm Charts, Pyspark, Azure Data Factory, Azure Cosmos, AKS, Airflow,
Kubernetes</p>
<h3 id="achievements-2">Achievements:</h3>
<ul>
<li>Led a SWAT team to increase the performance of pricing reports, we
managed to render a</li>
</ul>
<p>report in 15 seconds that was previously taking 15 minutes. Deployed
proof of concept airflow pipeline in Kubernetes that also has jobs that
run in AKS</p>
<ul>
<li>mentored junior members in development practice, GitHub, unit
testing, code-quality.</li>
<li>trained remote developers in Github, Git</li>
<li>wrote a data pipeline that ingests from google sheets which enabled
business analysts to collaborate on cargo tracking reference</li>
<li>introduced the team to event-driven architecture, which resulted in
10x speed of data processing.</li>
<li>used graph algorithms (using networks in python ) to enable</li>
</ul>
<p>visualization and therefore aid simplify complex decision paths in
business logic introduced BDD to help BAs verify business logic.</p>
<h2 id="september-2018-march-2019-quantexa">September 2018 – March 2019:
<a href="http://quantexa.com">Quantexa</a></h2>
<h3 id="senior-data-engineer">Senior Data Engineer</h3>
<h3 id="responsibilities-3">Responsibilities</h3>
<ul>
<li>Mentoring architecture and quality refactoring of Quantexa’s
award-winning analysis</li>
</ul>
<p>and fraud detection platform.</p>
<ul>
<li>A team member responsible for accelerating the code quality of
Quantexa implementations as they are rolled out onto banks; my
duties</li>
</ul>
<p>include code reviews of client implementations and code quality and
improvement of the core product.</p>
<h3 id="technologies-3">Technologies</h3>
<ul>
<li>GCP</li>
<li>Spark</li>
<li>Frameless</li>
<li>Scala</li>
<li>Spark testing framework</li>
<li>Cats</li>
<li>ScalaCheck</li>
<li>Git-lab</li>
<li>typesafe config</li>
</ul>
<h3 id="achievements-3">Achievements</h3>
<ul>
<li>Redesign and refactoring the core scoring framework.</li>
<li>Introduced property-based testing using ScalaCheck to bring</li>
</ul>
<p>test coverage over 90%</p>
<ul>
<li>Implementation of typesafe config for reducing release errors due to
misconfiguration</li>
</ul>
<h2 id="june-2017---january-2019-mydrive">June 2017 - January 2019: <a
href="http://mydrivesolutions.com">MyDrive</a></h2>
<h3 id="senior-data-engineer-1">Senior Data Engineer</h3>
<h3 id="responsibilities-4">Responsibilities</h3>
<p>Design and implementation of MyDrive Data Lake ETL process Ad-Hoc
Data Cleansing for DataScientists</p>
<h3 id="technologies-4">Technologies</h3>
<ul>
<li><a href="https://aws.amazon.com/rds/">AWS</a>
<ul>
<li><a href="https://aws.amazon.com/ec2/">EC2</a></li>
<li><a href="https://aws.amazon.com/emr/">EMR</a>
<ul>
<li>automation</li>
</ul></li>
<li><a href="https://aws.amazon.com/s3/">S3</a></li>
<li><a href="http://jupyter.org/">Jupyter-Notebooks</a></li>
<li>Lambda</li>
<li><a href="https://aws.amazon.com/redshift/">Redshift</a></li>
<li><a href="https://aws.amazon.com/rds/">RDS</a>
<ul>
<li><a href="https://www.postgresql.org/">postgres</a></li>
</ul></li>
<li>Data visualization
<ul>
<li><a href="https://matplotlib.org/">Matlplotlib</a></li>
</ul></li>
</ul></li>
<li><a href="http://answerrocket.com/">AnswerRocket</a></li>
<li><a href="https://hive.apache.org/">hive</a>
<ul>
<li>Hive performance tuning</li>
</ul></li>
<li><a href="http://www.scala-lang.org/">Scala 2.11.6 (for EMR
compatibility)</a></li>
<li><a href="https://www.haskell.org/">Haskell (GHC 8.0.1)</a></li>
<li><a href="https://clojure.org/">clojure</a></li>
<li><a href="http://spark.apache.org/">Spark 2.1.0 ( for EMR
compatibility)</a></li>
<li><a href="https://nlp.stanford.edu/projects/glove/">Glove (python
implementation of word2vec)</a></li>
<li><a href="https://pymc-devs.github.io/pymc/">PyMc (for Bayesian
analysis)</a></li>
<li><a href="https://parquet.apache.org/">Parquet</a></li>
<li><a href="https://www.nginx.com/">Nginx</a></li>
<li><a href="https://about.gitlab.com/">Gitlab</a></li>
</ul>
<h3 id="achievements-4">Achievements</h3>
<ul>
<li>Co-Design and implementation of a Data Lake for organizing the
ingestion and processing locations of OLTP /OLAP data streams in
scala/spark, airflow</li>
<li>Audit of all of MyDrive data on S3 for GDPR, currently around
30TB</li>
<li>Introduced the best industry standards for python development; via
type-based Python (mypy) better virtualization (pipenv) and a stronger
project framework</li>
<li>began to learn some production-level terraform for cloud-agnostic
infrastructure</li>
</ul>
<h3 id="skills-gained">Skills Gained</h3>
<ul>
<li>AWS Lambda</li>
<li>AWS DMS</li>
<li>AWS Athena</li>
<li>AWS Glue</li>
<li>Apache Airflow</li>
<li>AWS ECS</li>
<li>AWS ECR</li>
<li>AWS Kinesis</li>
<li>Mypy</li>
<li>Terraform</li>
<li>Boto3</li>
</ul>
<h2 id="july-2016---april-2017-aimia">July 2016 - April 2017: <a
href="https://www.aimia.com/">Aimia</a></h2>
<h3 id="machine-learning-engineer">Machine Learning Engineer</h3>
<h3 id="responsibilities-5">Responsibilities</h3>
<p>Working within a new team for monetizing Aimia's vast data
repository. My responsibilities initially were helping migrate Aimia's
data processing services to a more robust platform (EMR). I then moved
into co-designing and developing a platform to capture all the data
needed for the machine-learning techniques we wished to use. This
completed, I then developed real-time ETL spark streams for data out of
the legacy hive data warehouse so data could easily be used in a variety
of machine learning algorithms. Choosing parquet because of its schema
evolution and performance properties. I completed a brief prototype
migration to the <a href="http://answerrocket.com/">answer rocket</a>
platform so that some less technical analysts could evaluate natural
language analytics.</p>
<h3 id="technologies-5">Technologies</h3>
<ul>
<li><a href="https://aws.amazon.com/rds/">AWS</a>
<ul>
<li><a href="https://aws.amazon.com/ec2/">EC2</a></li>
<li><a href="https://aws.amazon.com/emr/">EMR</a>
<ul>
<li>automation</li>
</ul></li>
<li><a href="https://aws.amazon.com/s3/">S3</a></li>
<li><a href="http://jupyter.org/">Jupyter-Notebooks</a></li>
<li>Lambda</li>
<li><a href="https://aws.amazon.com/redshift/">Redshift</a></li>
<li><a href="https://aws.amazon.com/rds/">RDS</a>
<ul>
<li><a href="https://www.postgresql.org/">postgres</a></li>
</ul></li>
<li>Data visualization
<ul>
<li><a href="https://matplotlib.org/">Matlplotlib</a></li>
</ul></li>
</ul></li>
<li><a href="http://answerrocket.com/">AnswerRocket</a></li>
<li><a href="https://hive.apache.org/">hive</a>
<ul>
<li>Hive performance tuning</li>
</ul></li>
<li><a href="http://www.scala-lang.org/">Scala 2.11.6 (for EMR
compatibility)</a></li>
<li><a href="https://www.haskell.org/">Haskell (GHC 8.0.1)</a></li>
<li><a href="https://clojure.org/">clojure</a></li>
<li><a href="http://spark.apache.org/">Spark 2.1.0 ( for EMR
compatibility)</a></li>
<li><a href="https://nlp.stanford.edu/projects/glove/">Glove (python
implementation of word2vec)</a></li>
<li><a href="https://pymc-devs.github.io/pymc/">PyMc (for Bayesian
analysis)</a></li>
<li><a href="https://parquet.apache.org/">Parquet</a></li>
<li><a href="https://www.nginx.com/">Nginx</a></li>
<li><a href="https://about.gitlab.com/">Gitlab</a></li>
</ul>
<h3 id="achievements-5">Achievements</h3>
<ul>
<li>Set up Continuous Integration and Unit Testing Infrastructure</li>
<li>Helped complete migration from EC2 to EMR for greater resilience to
failure</li>
<li>Implemented an HQL (Hive SQL) Parser in Haskell to auto-generate
Spark streaming schema from the abstract syntax tree</li>
<li>Engineered, Designed and developed real-time streaming for the
majority of data warehouse into big-data platform in AWS</li>
<li>Helped set up the continuous integration environment</li>
<li>Implemented word2vec for cluster classification of websites</li>
<li>Made a prototype answer rocket database for an evaluation of natural
language analytics</li>
</ul>
<h3 id="skills-gained-1">Skills Gained</h3>
<p>AWS Clojure Nginx Docker Kafka Bayesian Analysis (PyMC)</p>
<h2 id="april-2015---june-2016-self-employed-barclays-capital">April
2015 - June 2016, Self Employed: <a
href="https://www.cib.barclays/">Barclays Capital</a></h2>
<h3 id="big-data-etl-engineer">Big Data ETL Engineer</h3>
<h3 id="responsibilities-6">Responsibilities</h3>
<p>Ingesting Risk Data into Barclays BigData System Design meetings and
code quality</p>
<h3 id="technologies-6">Technologies</h3>
<ul>
<li>Hadoop</li>
<li>Apache Spark</li>
<li>Apache Flume</li>
<li>Kafka</li>
<li>Protobuf/Parquet/Avro</li>
<li>Berkley DB</li>
</ul>
<h3 id="achievements-6">Achievements</h3>
<ul>
<li>Set up Continuous Integration and Unit Testing Infrastructure</li>
<li>developed systems to ingest terabytes of risk profile data into
hdfs</li>
<li>helped set up a continuous integration environment</li>
<li>helped mentor graduate intern</li>
<li>developed comprehensive testing using ScalaCheck test
generation</li>
<li>integrated apache flume with Barclays in-house data warehouse
format</li>
<li>re-engineered Barclays interface to Solace Messaging in Scala</li>
</ul>
<h3 id="skills-gained-2">Skills Gained</h3>
<p>Apache Flume Apache Spark ScalaCheck Solace Messaging Kafka</p>
<h2 id="september-2014---february-2015-blinkbox-books">September 2014 -
February 2015, Blinkbox Books</h2>
<h3 id="senior-scala-engineer">Senior Scala Engineer</h3>
<h3 id="responsibilities-7">Responsibilities</h3>
<ul>
<li>Design of and implementation of REST APIs, in swagger</li>
<li>Automated verification of APIs against swagger in Tests</li>
<li>Wrote property-based testing code for storage service</li>
<li>Interfacing with Microsoft Azure Storage Framework with Scala</li>
<li>Implementation of Scala code</li>
<li>Writing functional tests in Property Based BDD style
<ul>
<li>ScalaCheck Property</li>
<li>FlatSpec for BDD</li>
</ul></li>
<li>Review and Merging of Pull Requests in Git hub</li>
<li>Diagnosis of issues with Continuous Integration and Deployment
preparation</li>
<li>AMQP configuration</li>
</ul>
<h3 id="technologies-7">Technologies</h3>
<ul>
<li>Scala</li>
<li>ScalaCheck</li>
<li>Spray.io</li>
<li>FlatSpec</li>
<li>Akka</li>
<li>Github, Git</li>
<li>Swagger</li>
<li>REST</li>
<li>HTTP</li>
<li>Azure</li>
<li>RabbitMQ AMQP</li>
</ul>
<h3 id="achievements-7">Achievements</h3>
<ul>
<li>Designed, Developed and Deployed the first version of REST endpoint
for storage agnostic cloud-based big data service, with redundancy
across storage providers</li>
<li>Improved Scala, Git, Github, REST knowledge, AMQP/RabbitMQ
knowledge</li>
</ul>
<h3 id="skills-gained-3">Skills Gained</h3>
<ul>
<li>AMQP/ RabbitMQ</li>
<li>REST</li>
<li>Spray.io/ Akka</li>
</ul>
<h2 id="august-2013---august-2014-rbs">August 2013 - August 2014, <a
href="https://www.rbs.co.uk/">RBS</a></h2>
<h3 id="infrastructure-developer">Infrastructure Developer</h3>
<p>Working with the maintenance and monitoring of RBS’s big-data risk
aggregation platform. I used a combination of</p>
<ul>
<li>java 6</li>
<li>oracle coherence</li>
<li>Unix bash shell scripts</li>
<li>Haskell</li>
<li>Scala</li>
<li>Python</li>
</ul>
<p>I am responsible for</p>
<ul>
<li>capacity planning</li>
<li>monitoring bandwidth throughput and latency to ensure the smooth
running of the platform.</li>
<li>Bidding for budget and rationalizing legacy infrastructure.</li>
</ul>
<h3 id="responsibilities-8">Responsibilities</h3>
<ul>
<li>Dev Ops</li>
<li>Capacity management</li>
<li>Infrastructure Bidding.</li>
<li>Technologies
<ul>
<li>Java 6</li>
<li>Python</li>
<li>Scala</li>
<li>Scalaz</li>
<li>Continuous Integration (TeamCity)</li>
<li>Dev-ops</li>
<li>Coherence
<ul>
<li>capacity planning</li>
<li>performance profiling</li>
</ul></li>
<li>Scala-sbt</li>
<li>ScalaCheck</li>
<li>Scala-Specs</li>
</ul></li>
</ul>
<h3 id="skills-gained-4">Skills Gained</h3>
<ul>
<li>Bidding</li>
<li>Budgeting</li>
<li>Coherence
<ul>
<li>performance</li>
<li>capacity analysis</li>
</ul></li>
<li>FX</li>
<li>Git</li>
<li>Scala</li>
<li>Scalaz</li>
<li>Scala Check</li>
<li>Scala Specs</li>
<li>Python</li>
<li>Haskell</li>
<li>DevOps</li>
<li>Scrum</li>
</ul>
<h3 id="achievements-8">Achievements</h3>
<ul>
<li>learned scrum/agile in depth here, gained in-depth knowledge of
scrum.</li>
<li>Recently developed a £500k proposal for new infrastructure as a
result of a profiling and capacity plan I put in place.</li>
<li>Presented plan to the RBS board and won approval for the spend for
updating the nodes in a coherence cluster based on profiling, coherence
cluster shock and datagram analysis measurements.</li>
<li>Dev-ops scripts written in Haskell</li>
<li>6 months of commercial advanced
<ul>
<li>Scala</li>
<li>Scalaz</li>
<li>ScalaCheck</li>
</ul></li>
</ul>
<h2 id="jun-2010-september-2013-ig-group">Jun 2010 – September 2013, <a
href="https://www.ig.com/uk">IG Group</a></h2>
<h3 id="direct-market-access-smart-order-routing-java-developer">Direct
Market Access &amp; Smart Order Routing Java Developer</h3>
<h3 id="responsibilities-9">Responsibilities</h3>
<ul>
<li>General FIX Connectivity</li>
<li>Instrument Downloads and Trading</li>
<li>Designed coded and accredited IG trading Gateways to be compliant
with external exchange trading protocols.</li>
<li>Daily instrument downloads from exchanges</li>
<li>API client connectivity and accreditation</li>
<li>Smart Order Routing (SOR)
<ul>
<li>tweaking SOR trading strategies</li>
<li>Fault Diagnosis and SOR Order Resolution</li>
</ul></li>
<li>certification with external companies</li>
<li>Last line of support for trading gateways and connectivity
issues</li>
</ul>
<h3 id="technologies-8">Technologies</h3>
<ul>
<li>Java 6</li>
<li>Java 7</li>
<li>LMAX disruptor</li>
<li>Multi-threading</li>
<li>Linux</li>
<li>Oracle SQL</li>
<li>SQL Developer</li>
<li>Clover</li>
<li>Sonar</li>
<li>Maven2</li>
<li>Maven 3</li>
<li>Bamboo</li>
<li>Python 2.6</li>
<li>Python-Requests</li>
<li>BDD</li>
<li>JBehave</li>
<li>Domain-Driven Design</li>
<li>Concurrent Programming Functional Programming</li>
<li>Low Latency Algorithms</li>
<li>Disruptor Pattern</li>
<li>Bash Shell Scripting</li>
</ul>
<h3 id="achievements-9">Achievements</h3>
<ul>
<li>Introduced BDD/TDD to the team and increased productivity by
20%</li>
<li>Designed and implemented the initial framework for IG’s
Gateways</li>
<li>CHIX, Bats,Bloomberg,CommerzBank, UBS</li>
<li>LSE, (Including its winning LSE Millennium Gateway,IG had no
downtime on LSE launch compared to 80% of finance houses)</li>
<li>Designed and implemented Connectivity for Algorithmic Exposure
Hedging System</li>
<li>Standardised a way to debug running processes across multiple
firewalled SSL zones</li>
<li>Introduced BDD and Domain Driven Design to the DMA Connectivity
team</li>
</ul>
<h3 id="skills-gained-5">Skills Gained</h3>
<ul>
<li>Trading</li>
<li>FX</li>
<li>Securities</li>
<li>EasyMock Mockito</li>
<li>JBehave</li>
<li>SOR</li>
<li>Order Routing</li>
<li>Trading</li>
<li>FIX 4.2</li>
<li>FIX5SP2</li>
<li>Cameron</li>
<li>git-svn</li>
</ul>
<h2 id="apr-2008-june-2009stan-james">Apr 2008 – June 2009,<a
href="http://stanjames-betting.com/">Stan James</a></h2>
<p>Working with a top gambling company; Developing a trading platform
and desktop application for traders in sports betting. I played key
roles in technical decision making, agile estimating, planning and
retrospectives, as well as implementation, testing, refactoring and
maintenance. Initially responsible for the inception of the quants
module for event pricing and later contributed all other modules.</p>
<h3 id="skills-gained-6">Skills Gained</h3>
<ul>
<li>Agile Methodology</li>
<li>Scrum</li>
<li>Agile Estimating and Planning</li>
<li>Sports Betting</li>
<li>GWT</li>
<li>Java Swing</li>
<li>Selenium</li>
<li>Fitness</li>
<li>Oracle Coherence</li>
<li>Hibernate</li>
<li>Spring</li>
<li>core Java</li>
<li>JUnit</li>
<li>Weblogic</li>
<li>Oracle</li>
</ul>
<h1 id="education">Education</h1>
<h2 id="university-college-london">2002-2003 University College
London</h2>
<h3 id="m.sc.-intelligent-systems-incomplete">M.Sc. Intelligent Systems
(Incomplete)</h3>
<ol>
<li><p>Course Content</p>
<ul>
<li>Neural Networks</li>
<li>SVMs</li>
<li>Decision Trees</li>
<li>Learning theory</li>
<li>Maximum Likelihood Estimation</li>
<li>Bayesian Decision Theory</li>
<li>Hidden Markov Models</li>
<li>EM Algorithm</li>
<li>ICA</li>
<li>Clustering</li>
<li>Factor Analysis</li>
<li>Mixture Models</li>
<li>Monte Carlo Sampling Methods</li>
<li>Graphs</li>
<li>Bayesian Networks</li>
</ul></li>
<li><p>Software Research paper:</p>
<p>Detecting Faces in Images a Survey of different approaches</p></li>
</ol>
<h2 id="university-of-birmingham">1994-1997 University of
Birmingham</h2>
<h3 id="i-b.sc.-computer-science-artificial-intelligence">2.I B.Sc.
Computer Science &amp; Artificial Intelligence</h3>
<ol>
<li><p>Course Content:</p>
<ul>
<li>Concurrent and Object Orientated Programming in C++</li>
<li>TCP-IP</li>
<li>UNIX real-time shared Memory and Semaphores</li>
<li>Computer Graphics</li>
<li>Advanced Interface Design</li>
<li>Human-Computer Interaction</li>
<li>Relational Database Theory</li>
<li>HTML Design / CGI Programming</li>
<li>Expert Systems</li>
<li>Neural Networks</li>
</ul></li>
<li><p>Software Research paper:</p>
<p>Melody Composition using Web-based Genetic Algorithms.</p></li>
</ol>
<h2 id="st-francis-xavier-college">1992-1994 St Francis Xavier
College</h2>
<p>3 A-levels including A in Computer Science</p>
<h2 id="john-paul-secondary-school">1987-1992 John Paul Secondary
School</h2>
<p>9 GCSE’s Grade A-C</p>
</body>
</html>
